{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae76b089",
   "metadata": {},
   "source": [
    "# Memory Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad856efe",
   "metadata": {},
   "source": [
    "## Channels Last Memory Format in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ce4e4",
   "metadata": {},
   "source": [
    "Channels last memory format is an alternative way of ordering NCHW tensors in memory preserving dimensions ordering. Channels last tensors ordered in such a way that channels become the densest dimension (aka storing images pixel-per-pixel).\n",
    "\n",
    "For example, classic (contiguous) storage of NCHW tensor (in our case it is two 4x4 images with 3 color channels) look like this:\n",
    "\n",
    "![classic_memory_format](./figs/classic_memory_format.png)\n",
    "\n",
    "Channels last memory format orders data differently:\n",
    "\n",
    "![channels_last_memory_format](./figs/channels_last_memory_format.png)\n",
    "\n",
    "\n",
    "Pytorch supports memory formats (and provides back compatibility with existing models including eager, JIT, and TorchScript) by utilizing  existing strides structure.\n",
    "For example, 10x3x16x16 batch in Channels last format will have strides equal to (768, 1, 48, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d09c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>NCHW stands for: batch N, channels C, depth D, height H, width W. It is a way to store multidimensional arrays / data frames / matrix into memory, which can be considered as a 1-D array.</p></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca8606",
   "metadata": {},
   "source": [
    "### Classic PyTorch contiguous tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a000e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3072, 1024, 32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N, C, H, W = 10, 3, 32, 32\n",
    "x = torch.empty(N, C, H, W)\n",
    "print(x.shape)  # Outputs: (10, 3, 32, 32) as dimensions order preserved\n",
    "x.stride()  # Ouputs: (3072, 1024, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725eb39e",
   "metadata": {},
   "source": [
    "**Conversion operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a3aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3072, 1, 96, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(memory_format=torch.channels_last)\n",
    "print(x.shape)  # Outputs: (10, 3, 32, 32) as dimensions order preserved\n",
    "x.stride()  # Outputs: (3072, 1, 96, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54776a1",
   "metadata": {},
   "source": [
    "**Back to contiguous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b978b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1024, 32, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(memory_format=torch.contiguous_format)\n",
    "x.stride()  # Outputs: (3072, 1024, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e1fb2",
   "metadata": {},
   "source": [
    "## Performance Gain \n",
    "\n",
    "The most significant performance gains are observed on NVIDIAâ€™s hardware with Tensor Cores support running on reduced precision (`torch.float16`). We are able to archive over 22% perf gains with channels last comparing to contiguous format, both while utilizing AMP (Automated Mixed Precision) training scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705212b",
   "metadata": {},
   "source": [
    "### Launch command\n",
    "\n",
    "**You need ImageNet to execute the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b40c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_level = O2\n",
      "keep_batchnorm_fp32 = None <class 'NoneType'>\n",
      "loss_scale = None <class 'NoneType'>\n",
      "\n",
      "CUDNN VERSION: 8204\n",
      "\n",
      "=> creating model 'resnet50'\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Traceback (most recent call last):\n",
      "  File \"code/main_amp.py\", line 543, in <module>\n",
      "    main()\n",
      "  File \"code/main_amp.py\", line 207, in main\n",
      "    train_dataset = datasets.ImageFolder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 310, in __init__\n",
      "    super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 145, in __init__\n",
      "    classes, class_to_idx = self.find_classes(self.root)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 221, in find_classes\n",
      "    return find_classes(directory)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 40, in find_classes\n",
      "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './data/train'\n"
     ]
    }
   ],
   "source": [
    "!python code/main_amp.py -a resnet50 --b 200 --workers 16 --opt-level O2 --channels-last true ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fcc60",
   "metadata": {},
   "source": [
    "## Credits/links\n",
    "- Vitaly Fedyunin <https://github.com/VitalyFedyunin>\n",
    "- https://github.com/apache/incubator-mxnet/issues/5778\n",
    "- https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f403a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
