{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452c0e9b",
   "metadata": {},
   "source": [
    "<p><center> <a href=\"../Start_Here.ipynb\"> Home Page</a> </center> </p> \n",
    "<div>\n",
    "    <span style=\"float: left; width:20%; text-align: left;\"><a href=\"06-DDP_Mixed_Precision.ipynb\" >Previous Notebook </a></span>\n",
    "    <span style=\"float: left; width:75%; text-align: right;\"><a href=\"04-ZeRO.ipynb\" >Next Notebook </a></span>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11985a",
   "metadata": {},
   "source": [
    "# Memory Format\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c37eb",
   "metadata": {},
   "source": [
    "## Channels Last Memory Format in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d5b66",
   "metadata": {},
   "source": [
    "Channels last memory format is an alternative way of ordering NCHW tensors in memory preserving dimensions ordering. Channels last tensors ordered in such a way that channels become the densest dimension (aka storing images pixel-per-pixel).\n",
    "\n",
    "For example, classic (contiguous) storage of NCHW tensor (in our case it is two 4x4 images with 3 color channels) look like this:\n",
    "\n",
    "![classic_memory_format](images/classic_memory_format.png)\n",
    "\n",
    "Channels last memory format orders data differently:\n",
    "\n",
    "![channels_last_memory_format](images/channels_last_memory_format.png)\n",
    "\n",
    "\n",
    "Pytorch supports memory formats (and provides back compatibility with existing models including eager, JIT, and TorchScript) by utilizing  existing strides structure.\n",
    "For example, `10x3x16x16` batch in Channels last format will have strides equal to `(768, 1, 48, 3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076d32f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>NCHW stands for: batch N, channels C, depth D, height H, width W. It is a way to store multidimensional arrays / data frames / matrix into memory, which can be considered as a 1-D array.</p></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad0c26",
   "metadata": {},
   "source": [
    "### Classic PyTorch contiguous tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eace5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N, C, H, W = 10, 3, 32, 32\n",
    "x = torch.empty(N, C, H, W)\n",
    "print(x.shape)  # Outputs: (10, 3, 32, 32) as dimensions order preserved\n",
    "x.stride()  # Ouputs: (3072, 1024, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40ae7a",
   "metadata": {},
   "source": [
    "**Conversion operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03716c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(memory_format=torch.channels_last)\n",
    "print(x.shape)  # Outputs: (10, 3, 32, 32) as dimensions order preserved\n",
    "x.stride()  # Outputs: (3072, 1, 96, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98b508",
   "metadata": {},
   "source": [
    "**Back to contiguous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(memory_format=torch.contiguous_format)\n",
    "x.stride()  # Outputs: (3072, 1024, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5792a185",
   "metadata": {},
   "source": [
    "## Performance Gain \n",
    "\n",
    "The most significant performance gains are observed on NVIDIAâ€™s hardware with Tensor Cores support running on reduced precision (`torch.float16`). We are able to archive over 22% perf gains with channels last comparing to contiguous format, both while utilizing AMP (Automated Mixed Precision) training scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1684a1c",
   "metadata": {},
   "source": [
    "### Launch command\n",
    "\n",
    "**You need ImageNet to execute the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../source_code/main_amp.py -a resnet50 --b 200 --workers 16 --opt-level O2 --channels-last true ../source_code/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b2806",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "- Vitaly Fedyunin <https://github.com/VitalyFedyunin>\n",
    "- https://github.com/apache/incubator-mxnet/issues/5778\n",
    "- https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f7e0c",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style=\"float: left; width:20%; text-align: left;\"><a href=\"06-DDP_Mixed_Precision.ipynb\" >Previous Notebook </a></span>\n",
    "    <span style=\"float: left; width:75%; text-align: right;\"><a href=\"04-ZeRO.ipynb\" >Next Notebook </a></span>\n",
    "</div>\n",
    "<br/>\n",
    "<p><center> <a href=\"../Start_Here.ipynb\"> Home Page</a> </center> </p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
