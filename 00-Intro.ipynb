{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8158f53d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e1e2e",
   "metadata": {},
   "source": [
    "The limited computation resource might discourage distibuted training across multiple GPUs. It’s basically an easy job to wrap the model with DDP (short for DistributedDataParallel). \n",
    "\n",
    "In this repo, I want to share code, insighs with all beginners in DDP. I’m not going to include detailed explanation of how DDP works, instead, I provide minimum knowledge needed to make the model run in multiple gpus. Note that I only introduce DDP on one machine with multiple gpus, which is the most general case (Otherwise, we should use model parallel as stated in the official [blog](https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c1cf5b",
   "metadata": {},
   "source": [
    "1. [Data Parallelism](01-Data_Parallelism.ipynb)\n",
    "1. [Model Parallelism](02-Model_Parallelism.ipynb)\n",
    "1. [Pipeline Parallelism](03-Pipeline_Parallelism.ipynb)\n",
    "1. [ZeRO](04-ZeRO.ipynb)\n",
    "1. [Memory Format](05-Memory_Format.ipynb)\n",
    "1. [Mixed Precision](06-DDP_Mixed_Precision.ipynb)\n",
    "1. [Message Passing](07-Message_Passing.ipynb)\n",
    "1. [Horovod](08-Horovod.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01634baa",
   "metadata": {},
   "source": [
    "# Application process topologies\n",
    "A Distributed Data Parallel (DDP) application can be executed on multiple nodes where each node can consist of multiple GPU devices. Each node in turn can run multiple copies of the DDP application, each of which processes its models on multiple GPUs.\n",
    "\n",
    "Let _N_ be the number of nodes on which the application is running and _G_ be the number of GPUs per node. The total number of application\n",
    "processes running across all the nodes at one time is called the **World Size**, _W_ and the number of processes running on each node\n",
    "is referred to as the **Local World Size**, _L_.\n",
    "\n",
    "Each application process is assigned two IDs: a _local_ rank in \\[0,_L_-1\\] and a _global_ rank in \\[0, _W_-1\\].\n",
    "\n",
    "To illustrate the terminology defined above, consider the case where a DDP application is launched on two nodes, each of which has four GPUs. We would then like each process to span two GPUs each. The mapping of processes to nodes is shown in the figure below:\n",
    "\n",
    "![ProcessMapping](https://user-images.githubusercontent.com/875518/77676984-4c81e400-6f4c-11ea-87d8-f2ff505a99da.png)\n",
    "\n",
    "While there are quite a few ways to map processes to nodes, a good rule of thumb is to have one process span a single GPU. This enables the DDP application to have as many parallel reader streams as there are GPUs and in practice provides a good balance between I/O and computational costs. In the rest of this tutorial, we assume that the application follows this heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2d3e4",
   "metadata": {},
   "source": [
    "### Get familiar with the system architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c3ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[4mGPU0\tGPU1\tGPU2\tGPU3\tCPU Affinity\u001b[0m\n",
      "GPU0\t X \tNV1\tNV1\tNV2\t0-39\n",
      "GPU1\tNV1\t X \tNV2\tNV1\t0-39\n",
      "GPU2\tNV1\tNV2\t X \tNV1\t0-39\n",
      "GPU3\tNV2\tNV1\tNV1\t X \t0-39\n",
      "\n",
      "Legend:\n",
      "\n",
      "  X    = Self\n",
      "  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n",
      "  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n",
      "  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n",
      "  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\n",
      "  PIX  = Connection traversing a single PCIe switch\n",
      "  NV#  = Connection traversing a bonded set of # NVLinks\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi topo -m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0249b",
   "metadata": {},
   "source": [
    "### Distributed launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1022a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "usage: launch.py [-h] [--nnodes NNODES] [--nproc_per_node NPROC_PER_NODE]\n",
      "                 [--rdzv_backend RDZV_BACKEND] [--rdzv_endpoint RDZV_ENDPOINT]\n",
      "                 [--rdzv_id RDZV_ID] [--rdzv_conf RDZV_CONF] [--standalone]\n",
      "                 [--max_restarts MAX_RESTARTS]\n",
      "                 [--monitor_interval MONITOR_INTERVAL]\n",
      "                 [--start_method {spawn,fork,forkserver}] [--role ROLE] [-m]\n",
      "                 [--no_python] [--run_path] [--log_dir LOG_DIR] [-r REDIRECTS]\n",
      "                 [-t TEE] [--node_rank NODE_RANK] [--master_addr MASTER_ADDR]\n",
      "                 [--master_port MASTER_PORT] [--use_env]\n",
      "                 training_script ...\n",
      "launch.py: error: the following arguments are required: training_script, training_script_args\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c89e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a60c40f",
   "metadata": {},
   "source": [
    "### Torchrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a0566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: torchrun [-h] [--nnodes NNODES] [--nproc_per_node NPROC_PER_NODE]\n",
      "                [--rdzv_backend RDZV_BACKEND] [--rdzv_endpoint RDZV_ENDPOINT]\n",
      "                [--rdzv_id RDZV_ID] [--rdzv_conf RDZV_CONF] [--standalone]\n",
      "                [--max_restarts MAX_RESTARTS]\n",
      "                [--monitor_interval MONITOR_INTERVAL]\n",
      "                [--start_method {spawn,fork,forkserver}] [--role ROLE] [-m]\n",
      "                [--no_python] [--run_path] [--log_dir LOG_DIR] [-r REDIRECTS]\n",
      "                [-t TEE] [--node_rank NODE_RANK] [--master_addr MASTER_ADDR]\n",
      "                [--master_port MASTER_PORT]\n",
      "                training_script ...\n",
      "torchrun: error: the following arguments are required: training_script, training_script_args\n"
     ]
    }
   ],
   "source": [
    "! torchrun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375270c",
   "metadata": {},
   "source": [
    "## Hot to run the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f35f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add reference to NGC container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5033457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
